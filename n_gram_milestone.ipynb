{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "832622a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:39:03.810418Z",
     "start_time": "2025-08-13T10:39:02.787804Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"import self-written function and classes\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from generator import to_byte_pair,generate\n",
    "from n_gram import N_gram\n",
    "from utility_functions import get_top_bigrams,get_words\n",
    "from utility_functions import generate_n_grams\n",
    "from BPE_function import bpe,get_best_merges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c8a1857",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:39:05.486933Z",
     "start_time": "2025-08-13T10:39:03.833468Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"load Shakespeare text (train,validation,test) that is converted into byte pairs (computed from bpe task)\"\"\"\n",
    "with open (r\"corpora/Shakespeare_byte.txt\", 'r') as f:\n",
    "  n_gram_corps_train = eval(f.read())\n",
    "with open (r\"corpora/Shakespeare_byte_valid.txt\", 'r') as f:\n",
    "  n_gram_corps_valid = eval(f.read())\n",
    "with open (r\"corpora/Shakespeare_byte_test.txt\", 'r') as f:\n",
    "  n_gram_corps_test = eval(f.read())\n",
    "with open (r\"corpora/vocab_train.txt\", 'r') as f:\n",
    "  vocab_train = eval(f.read())\n",
    "\n",
    "with open (r\"corpora/Shakespeare_clean_train.txt\", 'r') as f:\n",
    "  text_train = f.read()\n",
    "with open (r\"corpora/Shakespeare_clean_valid.txt\", 'r') as f:\n",
    "  text_valid = f.read()\n",
    "with open (r\"corpora/Shakespeare_clean_test.txt\", 'r') as f:\n",
    "  text_test = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cec6353",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:49:31.882213Z",
     "start_time": "2025-08-13T10:39:41.585609Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-gram split for 1-gram, k = 300: [['the_'], ['t'], ['ra'], ['g'], ['e'], ['dy_'], ['of_'], ['antony_'], ['and_'], ['c']]\n",
      "Old perplexity: 100000000.00106244\n",
      "Perplexity: 209.87\n",
      "N-gram split for 2-gram, k = 300: [['the_', 't'], ['t', 'ra'], ['ra', 'g'], ['g', 'e'], ['e', 'dy_'], ['dy_', 'of_'], ['of_', 'antony_'], ['antony_', 'and_'], ['and_', 'c'], ['c', 'le']]\n",
      "Old perplexity: 64.62248649372009\n",
      "Perplexity: 51.44\n",
      "N-gram split for 3-gram, k = 300: [['the_', 't', 'ra'], ['t', 'ra', 'g'], ['ra', 'g', 'e'], ['g', 'e', 'dy_'], ['e', 'dy_', 'of_'], ['dy_', 'of_', 'antony_'], ['of_', 'antony_', 'and_'], ['antony_', 'and_', 'c'], ['and_', 'c', 'le'], ['c', 'le', 'op']]\n",
      "Old perplexity: 1509.4546667103627\n",
      "Perplexity: 107.95\n",
      "N-gram split for 4-gram, k = 300: [['the_', 't', 'ra', 'g'], ['t', 'ra', 'g', 'e'], ['ra', 'g', 'e', 'dy_'], ['g', 'e', 'dy_', 'of_'], ['e', 'dy_', 'of_', 'antony_'], ['dy_', 'of_', 'antony_', 'and_'], ['of_', 'antony_', 'and_', 'c'], ['antony_', 'and_', 'c', 'le'], ['and_', 'c', 'le', 'op'], ['c', 'le', 'op', 'at']]\n",
      "Old perplexity: 80682.91442746914\n",
      "Perplexity: 220.25\n",
      "N-gram split for 1-gram, k = 400: [['the_'], ['t'], ['ra'], ['g'], ['e'], ['dy_'], ['of_'], ['antony_'], ['and_'], ['cleopatra_']]\n",
      "Old perplexity: 100000000.0008713\n",
      "Perplexity: 252.13\n",
      "N-gram split for 2-gram, k = 400: [['the_', 't'], ['t', 'ra'], ['ra', 'g'], ['g', 'e'], ['e', 'dy_'], ['dy_', 'of_'], ['of_', 'antony_'], ['antony_', 'and_'], ['and_', 'cleopatra_'], ['cleopatra_', 'd']]\n",
      "Old perplexity: 88.29872664728587\n",
      "Perplexity: 61.38\n",
      "N-gram split for 3-gram, k = 400: [['the_', 't', 'ra'], ['t', 'ra', 'g'], ['ra', 'g', 'e'], ['g', 'e', 'dy_'], ['e', 'dy_', 'of_'], ['dy_', 'of_', 'antony_'], ['of_', 'antony_', 'and_'], ['antony_', 'and_', 'cleopatra_'], ['and_', 'cleopatra_', 'd'], ['cleopatra_', 'd', 'ra']]\n",
      "Old perplexity: 3757.0822394115635\n",
      "Perplexity: 154.85\n",
      "N-gram split for 4-gram, k = 400: [['the_', 't', 'ra', 'g'], ['t', 'ra', 'g', 'e'], ['ra', 'g', 'e', 'dy_'], ['g', 'e', 'dy_', 'of_'], ['e', 'dy_', 'of_', 'antony_'], ['dy_', 'of_', 'antony_', 'and_'], ['of_', 'antony_', 'and_', 'cleopatra_'], ['antony_', 'and_', 'cleopatra_', 'd'], ['and_', 'cleopatra_', 'd', 'ra'], ['cleopatra_', 'd', 'ra', 'ma']]\n",
      "Old perplexity: 177471.51961496245\n",
      "Perplexity: 279.94\n",
      "N-gram split for 1-gram, k = 500: [['the_'], ['t'], ['ra'], ['g'], ['e'], ['dy_'], ['of_'], ['antony_'], ['and_'], ['cleopatra_']]\n",
      "Old perplexity: 100000000.0007068\n",
      "Perplexity: 288.99\n",
      "N-gram split for 2-gram, k = 500: [['the_', 't'], ['t', 'ra'], ['ra', 'g'], ['g', 'e'], ['e', 'dy_'], ['dy_', 'of_'], ['of_', 'antony_'], ['antony_', 'and_'], ['and_', 'cleopatra_'], ['cleopatra_', 'd']]\n",
      "Old perplexity: 121.45166762420037\n",
      "Perplexity: 72.93\n",
      "N-gram split for 3-gram, k = 500: [['the_', 't', 'ra'], ['t', 'ra', 'g'], ['ra', 'g', 'e'], ['g', 'e', 'dy_'], ['e', 'dy_', 'of_'], ['dy_', 'of_', 'antony_'], ['of_', 'antony_', 'and_'], ['antony_', 'and_', 'cleopatra_'], ['and_', 'cleopatra_', 'd'], ['cleopatra_', 'd', 'ra']]\n",
      "Old perplexity: 7880.039482517996\n",
      "Perplexity: 205.72\n",
      "N-gram split for 4-gram, k = 500: [['the_', 't', 'ra', 'g'], ['t', 'ra', 'g', 'e'], ['ra', 'g', 'e', 'dy_'], ['g', 'e', 'dy_', 'of_'], ['e', 'dy_', 'of_', 'antony_'], ['dy_', 'of_', 'antony_', 'and_'], ['of_', 'antony_', 'and_', 'cleopatra_'], ['antony_', 'and_', 'cleopatra_', 'd'], ['and_', 'cleopatra_', 'd', 'ra'], ['cleopatra_', 'd', 'ra', 'ma']]\n",
      "Old perplexity: 319011.89695302973\n",
      "Perplexity: 335.28\n",
      "N-gram split for 1-gram, k = 600: [['the_'], ['tra'], ['ge'], ['dy_'], ['of_'], ['antony_'], ['and_'], ['cleopatra_'], ['dr'], ['a']]\n",
      "Old perplexity: 100000000.00057927\n",
      "Perplexity: 322.70\n",
      "N-gram split for 2-gram, k = 600: [['the_', 'tra'], ['tra', 'ge'], ['ge', 'dy_'], ['dy_', 'of_'], ['of_', 'antony_'], ['antony_', 'and_'], ['and_', 'cleopatra_'], ['cleopatra_', 'dr'], ['dr', 'a'], ['a', 'ma']]\n",
      "Old perplexity: 162.25140881524266\n",
      "Perplexity: 85.16\n",
      "N-gram split for 3-gram, k = 600: [['the_', 'tra', 'ge'], ['tra', 'ge', 'dy_'], ['ge', 'dy_', 'of_'], ['dy_', 'of_', 'antony_'], ['of_', 'antony_', 'and_'], ['antony_', 'and_', 'cleopatra_'], ['and_', 'cleopatra_', 'dr'], ['cleopatra_', 'dr', 'a'], ['dr', 'a', 'ma'], ['a', 'ma', 'tis_']]\n",
      "Old perplexity: 13603.1418554953\n",
      "Perplexity: 254.31\n",
      "N-gram split for 4-gram, k = 600: [['the_', 'tra', 'ge', 'dy_'], ['tra', 'ge', 'dy_', 'of_'], ['ge', 'dy_', 'of_', 'antony_'], ['dy_', 'of_', 'antony_', 'and_'], ['of_', 'antony_', 'and_', 'cleopatra_'], ['antony_', 'and_', 'cleopatra_', 'dr'], ['and_', 'cleopatra_', 'dr', 'a'], ['cleopatra_', 'dr', 'a', 'ma'], ['dr', 'a', 'ma', 'tis_'], ['a', 'ma', 'tis_', 'per']]\n",
      "Old perplexity: 486475.4220297373\n",
      "Perplexity: 388.53\n",
      "N-gram split for 1-gram, k = 700: [['the_'], ['tra'], ['ge'], ['dy_'], ['of_'], ['antony_'], ['and_'], ['cleopatra_'], ['dra'], ['ma']]\n",
      "Old perplexity: 100000000.00046131\n",
      "Perplexity: 353.02\n",
      "N-gram split for 2-gram, k = 700: [['the_', 'tra'], ['tra', 'ge'], ['ge', 'dy_'], ['dy_', 'of_'], ['of_', 'antony_'], ['antony_', 'and_'], ['and_', 'cleopatra_'], ['cleopatra_', 'dra'], ['dra', 'ma'], ['ma', 'tis_']]\n",
      "Old perplexity: 212.30167818995182\n",
      "Perplexity: 98.55\n",
      "N-gram split for 3-gram, k = 700: [['the_', 'tra', 'ge'], ['tra', 'ge', 'dy_'], ['ge', 'dy_', 'of_'], ['dy_', 'of_', 'antony_'], ['of_', 'antony_', 'and_'], ['antony_', 'and_', 'cleopatra_'], ['and_', 'cleopatra_', 'dra'], ['cleopatra_', 'dra', 'ma'], ['dra', 'ma', 'tis_'], ['ma', 'tis_', 'per']]\n",
      "Old perplexity: 21842.274997184468\n",
      "Perplexity: 306.62\n",
      "N-gram split for 4-gram, k = 700: [['the_', 'tra', 'ge', 'dy_'], ['tra', 'ge', 'dy_', 'of_'], ['ge', 'dy_', 'of_', 'antony_'], ['dy_', 'of_', 'antony_', 'and_'], ['of_', 'antony_', 'and_', 'cleopatra_'], ['antony_', 'and_', 'cleopatra_', 'dra'], ['and_', 'cleopatra_', 'dra', 'ma'], ['cleopatra_', 'dra', 'ma', 'tis_'], ['dra', 'ma', 'tis_', 'per'], ['ma', 'tis_', 'per', 'so']]\n",
      "Old perplexity: 693316.4545818109\n",
      "Perplexity: 437.31\n",
      "N-gram split for 1-gram, k = 800: [['the_'], ['tra'], ['ge'], ['dy_'], ['of_'], ['antony_'], ['and_'], ['cleopatra_'], ['dra'], ['ma']]\n",
      "Old perplexity: 100000000.00037001\n",
      "Perplexity: 377.92\n",
      "N-gram split for 2-gram, k = 800: [['the_', 'tra'], ['tra', 'ge'], ['ge', 'dy_'], ['dy_', 'of_'], ['of_', 'antony_'], ['antony_', 'and_'], ['and_', 'cleopatra_'], ['cleopatra_', 'dra'], ['dra', 'ma'], ['ma', 'tis_']]\n",
      "Old perplexity: 268.95899145096445\n",
      "Perplexity: 112.09\n",
      "N-gram split for 3-gram, k = 800: [['the_', 'tra', 'ge'], ['tra', 'ge', 'dy_'], ['ge', 'dy_', 'of_'], ['dy_', 'of_', 'antony_'], ['of_', 'antony_', 'and_'], ['antony_', 'and_', 'cleopatra_'], ['and_', 'cleopatra_', 'dra'], ['cleopatra_', 'dra', 'ma'], ['dra', 'ma', 'tis_'], ['ma', 'tis_', 'per']]\n",
      "Old perplexity: 30540.916986443233\n",
      "Perplexity: 354.01\n",
      "N-gram split for 4-gram, k = 800: [['the_', 'tra', 'ge', 'dy_'], ['tra', 'ge', 'dy_', 'of_'], ['ge', 'dy_', 'of_', 'antony_'], ['dy_', 'of_', 'antony_', 'and_'], ['of_', 'antony_', 'and_', 'cleopatra_'], ['antony_', 'and_', 'cleopatra_', 'dra'], ['and_', 'cleopatra_', 'dra', 'ma'], ['cleopatra_', 'dra', 'ma', 'tis_'], ['dra', 'ma', 'tis_', 'per'], ['ma', 'tis_', 'per', 'so']]\n",
      "Old perplexity: 863517.314609638\n",
      "Perplexity: 481.45\n",
      "N-gram split for 1-gram, k = 900: [['the_'], ['tra'], ['ge'], ['dy_'], ['of_'], ['antony_'], ['and_'], ['cleopatra_'], ['dra'], ['ma']]\n",
      "Old perplexity: 100000000.00030002\n",
      "Perplexity: 399.78\n",
      "N-gram split for 2-gram, k = 900: [['the_', 'tra'], ['tra', 'ge'], ['ge', 'dy_'], ['dy_', 'of_'], ['of_', 'antony_'], ['antony_', 'and_'], ['and_', 'cleopatra_'], ['cleopatra_', 'dra'], ['dra', 'ma'], ['ma', 'tis_']]\n",
      "Old perplexity: 326.6586386889279\n",
      "Perplexity: 124.95\n",
      "N-gram split for 3-gram, k = 900: [['the_', 'tra', 'ge'], ['tra', 'ge', 'dy_'], ['ge', 'dy_', 'of_'], ['dy_', 'of_', 'antony_'], ['of_', 'antony_', 'and_'], ['antony_', 'and_', 'cleopatra_'], ['and_', 'cleopatra_', 'dra'], ['cleopatra_', 'dra', 'ma'], ['dra', 'ma', 'tis_'], ['ma', 'tis_', 'per']]\n",
      "Old perplexity: 39695.96872024733\n",
      "Perplexity: 399.87\n",
      "N-gram split for 4-gram, k = 900: [['the_', 'tra', 'ge', 'dy_'], ['tra', 'ge', 'dy_', 'of_'], ['ge', 'dy_', 'of_', 'antony_'], ['dy_', 'of_', 'antony_', 'and_'], ['of_', 'antony_', 'and_', 'cleopatra_'], ['antony_', 'and_', 'cleopatra_', 'dra'], ['and_', 'cleopatra_', 'dra', 'ma'], ['cleopatra_', 'dra', 'ma', 'tis_'], ['dra', 'ma', 'tis_', 'per'], ['ma', 'tis_', 'per', 'so']]\n",
      "Old perplexity: 1040109.1982249514\n",
      "Perplexity: 525.73\n",
      "N-gram split for 1-gram, k = 1000: [['the_'], ['tra'], ['ge'], ['dy_'], ['of_'], ['antony_'], ['and_'], ['cleopatra_'], ['dra'], ['ma']]\n",
      "Old perplexity: 100000000.00022826\n",
      "Perplexity: 420.41\n",
      "N-gram split for 2-gram, k = 1000: [['the_', 'tra'], ['tra', 'ge'], ['ge', 'dy_'], ['dy_', 'of_'], ['of_', 'antony_'], ['antony_', 'and_'], ['and_', 'cleopatra_'], ['cleopatra_', 'dra'], ['dra', 'ma'], ['ma', 'tis_']]\n",
      "Old perplexity: 396.42658779590926\n",
      "Perplexity: 139.62\n",
      "N-gram split for 3-gram, k = 1000: [['the_', 'tra', 'ge'], ['tra', 'ge', 'dy_'], ['ge', 'dy_', 'of_'], ['dy_', 'of_', 'antony_'], ['of_', 'antony_', 'and_'], ['antony_', 'and_', 'cleopatra_'], ['and_', 'cleopatra_', 'dra'], ['cleopatra_', 'dra', 'ma'], ['dra', 'ma', 'tis_'], ['ma', 'tis_', 'per']]\n",
      "Old perplexity: 51285.90941399911\n",
      "Perplexity: 450.02\n",
      "N-gram split for 4-gram, k = 1000: [['the_', 'tra', 'ge', 'dy_'], ['tra', 'ge', 'dy_', 'of_'], ['ge', 'dy_', 'of_', 'antony_'], ['dy_', 'of_', 'antony_', 'and_'], ['of_', 'antony_', 'and_', 'cleopatra_'], ['antony_', 'and_', 'cleopatra_', 'dra'], ['and_', 'cleopatra_', 'dra', 'ma'], ['cleopatra_', 'dra', 'ma', 'tis_'], ['dra', 'ma', 'tis_', 'per'], ['ma', 'tis_', 'per', 'so']]\n",
      "Old perplexity: 1240616.6026653207\n",
      "Perplexity: 570.02\n",
      "N-gram split for 1-gram, k = 1100: [['the_'], ['tra'], ['ge'], ['dy_'], ['of_'], ['antony_'], ['and_'], ['cleopatra_'], ['dra'], ['ma']]\n",
      "Old perplexity: 100000000.00016288\n",
      "Perplexity: 440.03\n",
      "N-gram split for 2-gram, k = 1100: [['the_', 'tra'], ['tra', 'ge'], ['ge', 'dy_'], ['dy_', 'of_'], ['of_', 'antony_'], ['antony_', 'and_'], ['and_', 'cleopatra_'], ['cleopatra_', 'dra'], ['dra', 'ma'], ['ma', 'tis_']]\n",
      "Old perplexity: 474.00264377906996\n",
      "Perplexity: 153.84\n",
      "N-gram split for 3-gram, k = 1100: [['the_', 'tra', 'ge'], ['tra', 'ge', 'dy_'], ['ge', 'dy_', 'of_'], ['dy_', 'of_', 'antony_'], ['of_', 'antony_', 'and_'], ['antony_', 'and_', 'cleopatra_'], ['and_', 'cleopatra_', 'dra'], ['cleopatra_', 'dra', 'ma'], ['dra', 'ma', 'tis_'], ['ma', 'tis_', 'per']]\n",
      "Old perplexity: 63101.81830661405\n",
      "Perplexity: 495.46\n",
      "N-gram split for 4-gram, k = 1100: [['the_', 'tra', 'ge', 'dy_'], ['tra', 'ge', 'dy_', 'of_'], ['ge', 'dy_', 'of_', 'antony_'], ['dy_', 'of_', 'antony_', 'and_'], ['of_', 'antony_', 'and_', 'cleopatra_'], ['antony_', 'and_', 'cleopatra_', 'dra'], ['and_', 'cleopatra_', 'dra', 'ma'], ['cleopatra_', 'dra', 'ma', 'tis_'], ['dra', 'ma', 'tis_', 'per'], ['ma', 'tis_', 'per', 'so']]\n",
      "Old perplexity: 1392080.4720511464\n",
      "Perplexity: 607.22\n",
      "N-gram split for 1-gram, k = 1200: [['the_'], ['tra'], ['ge'], ['dy_'], ['of_'], ['antony_'], ['and_'], ['cleopatra_'], ['dra'], ['ma']]\n",
      "Old perplexity: 100000000.00010462\n",
      "Perplexity: 456.23\n",
      "N-gram split for 2-gram, k = 1200: [['the_', 'tra'], ['tra', 'ge'], ['ge', 'dy_'], ['dy_', 'of_'], ['of_', 'antony_'], ['antony_', 'and_'], ['and_', 'cleopatra_'], ['cleopatra_', 'dra'], ['dra', 'ma'], ['ma', 'tis_']]\n",
      "Old perplexity: 554.8065076604784\n",
      "Perplexity: 168.66\n",
      "N-gram split for 3-gram, k = 1200: [['the_', 'tra', 'ge'], ['tra', 'ge', 'dy_'], ['ge', 'dy_', 'of_'], ['dy_', 'of_', 'antony_'], ['of_', 'antony_', 'and_'], ['antony_', 'and_', 'cleopatra_'], ['and_', 'cleopatra_', 'dra'], ['cleopatra_', 'dra', 'ma'], ['dra', 'ma', 'tis_'], ['ma', 'tis_', 'per']]\n",
      "Old perplexity: 76161.3231107478\n",
      "Perplexity: 539.36\n",
      "N-gram split for 4-gram, k = 1200: [['the_', 'tra', 'ge', 'dy_'], ['tra', 'ge', 'dy_', 'of_'], ['ge', 'dy_', 'of_', 'antony_'], ['dy_', 'of_', 'antony_', 'and_'], ['of_', 'antony_', 'and_', 'cleopatra_'], ['antony_', 'and_', 'cleopatra_', 'dra'], ['and_', 'cleopatra_', 'dra', 'ma'], ['cleopatra_', 'dra', 'ma', 'tis_'], ['dra', 'ma', 'tis_', 'per'], ['ma', 'tis_', 'per', 'so']]\n",
      "Old perplexity: 1566290.0873623332\n",
      "Perplexity: 640.26\n",
      "N-gram split for 1-gram, k = 1300: [['the_'], ['tra'], ['ge'], ['dy_'], ['of_'], ['antony_'], ['and_'], ['cleopatra_'], ['dra'], ['ma']]\n",
      "Old perplexity: 100000000.0000492\n",
      "Perplexity: 474.80\n",
      "N-gram split for 2-gram, k = 1300: [['the_', 'tra'], ['tra', 'ge'], ['ge', 'dy_'], ['dy_', 'of_'], ['of_', 'antony_'], ['antony_', 'and_'], ['and_', 'cleopatra_'], ['cleopatra_', 'dra'], ['dra', 'ma'], ['ma', 'tis_']]\n",
      "Old perplexity: 655.0676983663692\n",
      "Perplexity: 185.22\n",
      "N-gram split for 3-gram, k = 1300: [['the_', 'tra', 'ge'], ['tra', 'ge', 'dy_'], ['ge', 'dy_', 'of_'], ['dy_', 'of_', 'antony_'], ['of_', 'antony_', 'and_'], ['antony_', 'and_', 'cleopatra_'], ['and_', 'cleopatra_', 'dra'], ['cleopatra_', 'dra', 'ma'], ['dra', 'ma', 'tis_'], ['ma', 'tis_', 'per']]\n",
      "Old perplexity: 90737.95893641679\n",
      "Perplexity: 584.59\n",
      "N-gram split for 4-gram, k = 1300: [['the_', 'tra', 'ge', 'dy_'], ['tra', 'ge', 'dy_', 'of_'], ['ge', 'dy_', 'of_', 'antony_'], ['dy_', 'of_', 'antony_', 'and_'], ['of_', 'antony_', 'and_', 'cleopatra_'], ['antony_', 'and_', 'cleopatra_', 'dra'], ['and_', 'cleopatra_', 'dra', 'ma'], ['cleopatra_', 'dra', 'ma', 'tis_'], ['dra', 'ma', 'tis_', 'per'], ['ma', 'tis_', 'per', 'so']]\n",
      "Old perplexity: 1737908.6451774286\n",
      "Perplexity: 674.37\n",
      "N-gram split for 1-gram, k = 1400: [['the_'], ['tra'], ['ge'], ['dy_'], ['of_'], ['antony_'], ['and_'], ['cleopatra_'], ['dra'], ['ma']]\n",
      "Old perplexity: 99999999.99999449\n",
      "Perplexity: 491.76\n",
      "N-gram split for 2-gram, k = 1400: [['the_', 'tra'], ['tra', 'ge'], ['ge', 'dy_'], ['dy_', 'of_'], ['of_', 'antony_'], ['antony_', 'and_'], ['and_', 'cleopatra_'], ['cleopatra_', 'dra'], ['dra', 'ma'], ['ma', 'tis_']]\n",
      "Old perplexity: 762.0413989636465\n",
      "Perplexity: 201.98\n",
      "N-gram split for 3-gram, k = 1400: [['the_', 'tra', 'ge'], ['tra', 'ge', 'dy_'], ['ge', 'dy_', 'of_'], ['dy_', 'of_', 'antony_'], ['of_', 'antony_', 'and_'], ['antony_', 'and_', 'cleopatra_'], ['and_', 'cleopatra_', 'dra'], ['cleopatra_', 'dra', 'ma'], ['dra', 'ma', 'tis_'], ['ma', 'tis_', 'per']]\n",
      "Old perplexity: 107034.1886007162\n",
      "Perplexity: 631.53\n",
      "N-gram split for 4-gram, k = 1400: [['the_', 'tra', 'ge', 'dy_'], ['tra', 'ge', 'dy_', 'of_'], ['ge', 'dy_', 'of_', 'antony_'], ['dy_', 'of_', 'antony_', 'and_'], ['of_', 'antony_', 'and_', 'cleopatra_'], ['antony_', 'and_', 'cleopatra_', 'dra'], ['and_', 'cleopatra_', 'dra', 'ma'], ['cleopatra_', 'dra', 'ma', 'tis_'], ['dra', 'ma', 'tis_', 'per'], ['ma', 'tis_', 'per', 'son']]\n",
      "Old perplexity: 1917494.7086206304\n",
      "Perplexity: 707.11\n",
      "N-gram split for 1-gram, k = 1500: [['the_'], ['tra'], ['ge'], ['dy_'], ['of_'], ['antony_'], ['and_'], ['cleopatra_'], ['dra'], ['ma']]\n",
      "Old perplexity: 99999999.99993694\n",
      "Perplexity: 507.93\n",
      "N-gram split for 2-gram, k = 1500: [['the_', 'tra'], ['tra', 'ge'], ['ge', 'dy_'], ['dy_', 'of_'], ['of_', 'antony_'], ['antony_', 'and_'], ['and_', 'cleopatra_'], ['cleopatra_', 'dra'], ['dra', 'ma'], ['ma', 'tis_']]\n",
      "Old perplexity: 885.1298131908054\n",
      "Perplexity: 220.00\n",
      "N-gram split for 3-gram, k = 1500: [['the_', 'tra', 'ge'], ['tra', 'ge', 'dy_'], ['ge', 'dy_', 'of_'], ['dy_', 'of_', 'antony_'], ['of_', 'antony_', 'and_'], ['antony_', 'and_', 'cleopatra_'], ['and_', 'cleopatra_', 'dra'], ['cleopatra_', 'dra', 'ma'], ['dra', 'ma', 'tis_'], ['ma', 'tis_', 'per']]\n",
      "Old perplexity: 125310.3486702936\n",
      "Perplexity: 676.61\n",
      "N-gram split for 4-gram, k = 1500: [['the_', 'tra', 'ge', 'dy_'], ['tra', 'ge', 'dy_', 'of_'], ['ge', 'dy_', 'of_', 'antony_'], ['dy_', 'of_', 'antony_', 'and_'], ['of_', 'antony_', 'and_', 'cleopatra_'], ['antony_', 'and_', 'cleopatra_', 'dra'], ['and_', 'cleopatra_', 'dra', 'ma'], ['cleopatra_', 'dra', 'ma', 'tis_'], ['dra', 'ma', 'tis_', 'per'], ['ma', 'tis_', 'per', 'son']]\n",
      "Old perplexity: 2111749.6124474327\n",
      "Perplexity: 739.40\n",
      "N-gram split for 1-gram, k = 1600: [['the_'], ['tra'], ['ge'], ['dy_'], ['of_'], ['antony_'], ['and_'], ['cleopatra_'], ['dra'], ['ma']]\n",
      "Old perplexity: 99999999.99989146\n",
      "Perplexity: 521.21\n",
      "N-gram split for 2-gram, k = 1600: [['the_', 'tra'], ['tra', 'ge'], ['ge', 'dy_'], ['dy_', 'of_'], ['of_', 'antony_'], ['antony_', 'and_'], ['and_', 'cleopatra_'], ['cleopatra_', 'dra'], ['dra', 'ma'], ['ma', 'tis_']]\n",
      "Old perplexity: 1007.5148702329461\n",
      "Perplexity: 237.37\n",
      "N-gram split for 3-gram, k = 1600: [['the_', 'tra', 'ge'], ['tra', 'ge', 'dy_'], ['ge', 'dy_', 'of_'], ['dy_', 'of_', 'antony_'], ['of_', 'antony_', 'and_'], ['antony_', 'and_', 'cleopatra_'], ['and_', 'cleopatra_', 'dra'], ['cleopatra_', 'dra', 'ma'], ['dra', 'ma', 'tis_'], ['ma', 'tis_', 'per']]\n",
      "Old perplexity: 143317.30123870607\n",
      "Perplexity: 719.92\n",
      "N-gram split for 4-gram, k = 1600: [['the_', 'tra', 'ge', 'dy_'], ['tra', 'ge', 'dy_', 'of_'], ['ge', 'dy_', 'of_', 'antony_'], ['dy_', 'of_', 'antony_', 'and_'], ['of_', 'antony_', 'and_', 'cleopatra_'], ['antony_', 'and_', 'cleopatra_', 'dra'], ['and_', 'cleopatra_', 'dra', 'ma'], ['cleopatra_', 'dra', 'ma', 'tis_'], ['dra', 'ma', 'tis_', 'per'], ['ma', 'tis_', 'per', 'son']]\n",
      "Old perplexity: 2278977.9823297663\n",
      "Perplexity: 769.32\n",
      "N-gram split for 1-gram, k = 1700: [['the_'], ['tra'], ['ge'], ['dy_'], ['of_'], ['antony_'], ['and_'], ['cleopatra_'], ['dra'], ['ma']]\n",
      "Old perplexity: 99999999.99984741\n",
      "Perplexity: 535.22\n",
      "N-gram split for 2-gram, k = 1700: [['the_', 'tra'], ['tra', 'ge'], ['ge', 'dy_'], ['dy_', 'of_'], ['of_', 'antony_'], ['antony_', 'and_'], ['and_', 'cleopatra_'], ['cleopatra_', 'dra'], ['dra', 'ma'], ['ma', 'tis_']]\n",
      "Old perplexity: 1138.9978289437536\n",
      "Perplexity: 254.76\n",
      "N-gram split for 3-gram, k = 1700: [['the_', 'tra', 'ge'], ['tra', 'ge', 'dy_'], ['ge', 'dy_', 'of_'], ['dy_', 'of_', 'antony_'], ['of_', 'antony_', 'and_'], ['antony_', 'and_', 'cleopatra_'], ['and_', 'cleopatra_', 'dra'], ['cleopatra_', 'dra', 'ma'], ['dra', 'ma', 'tis_'], ['ma', 'tis_', 'per']]\n",
      "Old perplexity: 162196.6514812907\n",
      "Perplexity: 764.34\n",
      "N-gram split for 4-gram, k = 1700: [['the_', 'tra', 'ge', 'dy_'], ['tra', 'ge', 'dy_', 'of_'], ['ge', 'dy_', 'of_', 'antony_'], ['dy_', 'of_', 'antony_', 'and_'], ['of_', 'antony_', 'and_', 'cleopatra_'], ['antony_', 'and_', 'cleopatra_', 'dra'], ['and_', 'cleopatra_', 'dra', 'ma'], ['cleopatra_', 'dra', 'ma', 'tis_'], ['dra', 'ma', 'tis_', 'per'], ['ma', 'tis_', 'per', 'son']]\n",
      "Old perplexity: 2445658.1173345656\n",
      "Perplexity: 799.11\n",
      "N-gram split for 1-gram, k = 1800: [['the_'], ['tra'], ['ge'], ['dy_'], ['of_'], ['antony_'], ['and_'], ['cleopatra_'], ['dra'], ['ma']]\n",
      "Old perplexity: 99999999.99981046\n",
      "Perplexity: 544.98\n",
      "N-gram split for 2-gram, k = 1800: [['the_', 'tra'], ['tra', 'ge'], ['ge', 'dy_'], ['dy_', 'of_'], ['of_', 'antony_'], ['antony_', 'and_'], ['and_', 'cleopatra_'], ['cleopatra_', 'dra'], ['dra', 'ma'], ['ma', 'tis_']]\n",
      "Old perplexity: 1259.897661632249\n",
      "Perplexity: 271.19\n",
      "N-gram split for 3-gram, k = 1800: [['the_', 'tra', 'ge'], ['tra', 'ge', 'dy_'], ['ge', 'dy_', 'of_'], ['dy_', 'of_', 'antony_'], ['of_', 'antony_', 'and_'], ['antony_', 'and_', 'cleopatra_'], ['and_', 'cleopatra_', 'dra'], ['cleopatra_', 'dra', 'ma'], ['dra', 'ma', 'tis_'], ['ma', 'tis_', 'per']]\n",
      "Old perplexity: 179316.63671639792\n",
      "Perplexity: 805.61\n",
      "N-gram split for 4-gram, k = 1800: [['the_', 'tra', 'ge', 'dy_'], ['tra', 'ge', 'dy_', 'of_'], ['ge', 'dy_', 'of_', 'antony_'], ['dy_', 'of_', 'antony_', 'and_'], ['of_', 'antony_', 'and_', 'cleopatra_'], ['antony_', 'and_', 'cleopatra_', 'dra'], ['and_', 'cleopatra_', 'dra', 'ma'], ['cleopatra_', 'dra', 'ma', 'tis_'], ['dra', 'ma', 'tis_', 'per'], ['ma', 'tis_', 'per', 'son']]\n",
      "Old perplexity: 2593568.0483461902\n",
      "Perplexity: 824.74\n",
      "N-gram split for 1-gram, k = 1900: [['the_'], ['tra'], ['ge'], ['dy_'], ['of_'], ['antony_'], ['and_'], ['cleopatra_'], ['dra'], ['ma']]\n",
      "Old perplexity: 99999999.99977386\n",
      "Perplexity: 557.02\n",
      "N-gram split for 2-gram, k = 1900: [['the_', 'tra'], ['tra', 'ge'], ['ge', 'dy_'], ['dy_', 'of_'], ['of_', 'antony_'], ['antony_', 'and_'], ['and_', 'cleopatra_'], ['cleopatra_', 'dra'], ['dra', 'ma'], ['ma', 'tis_']]\n",
      "Old perplexity: 1403.824157628554\n",
      "Perplexity: 288.49\n",
      "N-gram split for 3-gram, k = 1900: [['the_', 'tra', 'ge'], ['tra', 'ge', 'dy_'], ['ge', 'dy_', 'of_'], ['dy_', 'of_', 'antony_'], ['of_', 'antony_', 'and_'], ['antony_', 'and_', 'cleopatra_'], ['and_', 'cleopatra_', 'dra'], ['cleopatra_', 'dra', 'ma'], ['dra', 'ma', 'tis_'], ['ma', 'tis_', 'per']]\n",
      "Old perplexity: 198504.33561609613\n",
      "Perplexity: 849.02\n",
      "N-gram split for 4-gram, k = 1900: [['the_', 'tra', 'ge', 'dy_'], ['tra', 'ge', 'dy_', 'of_'], ['ge', 'dy_', 'of_', 'antony_'], ['dy_', 'of_', 'antony_', 'and_'], ['of_', 'antony_', 'and_', 'cleopatra_'], ['antony_', 'and_', 'cleopatra_', 'dra'], ['and_', 'cleopatra_', 'dra', 'ma'], ['cleopatra_', 'dra', 'ma', 'tis_'], ['dra', 'ma', 'tis_', 'per'], ['ma', 'tis_', 'per', 'son']]\n",
      "Old perplexity: 2739817.346588197\n",
      "Perplexity: 852.15\n"
     ]
    }
   ],
   "source": [
    "with open (r\"corpora/Shakespeare_clean_valid.txt\", 'r') as f:\n",
    "  text_valid = f.read()\n",
    "  \n",
    "dict_train = get_words(text_train)\n",
    "dict_valid = get_words(text_valid)\n",
    "dict_test = get_words(text_test)\n",
    "\n",
    "best_k,best_perplexity,best_n_gram,second_best_k,second_best_perplexity,second_best_n_gram,third_best_k,third_best_perplexity,third_best_n_gram,ks,n_gram_num,perplexities = get_best_merges(dict_train,text_train,dict_valid,text_valid,300,2000,100)\n",
    "result = [\"best k:\",best_k,\"best n gram\", best_n_gram,\"best k perplexity:\",best_perplexity,\"2nd best k:\",second_best_k,\"2nd best n gram\", second_best_n_gram,\"2nd best k perplexity:\",second_best_perplexity,\"3rd best k:\",third_best_k,\"3rd best n gram\",third_best_n_gram,\"3rd best k perplexity:\",third_best_perplexity]\n",
    "with open(\"k_merges_n_gram.txt\", \"w\") as k_merges_n_gram:\n",
    "  for item in result:\n",
    "     k_merges_n_gram.write(f\"{item}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfc811be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:52:15.562242Z",
     "start_time": "2025-08-13T10:51:00.133190Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "with open(\"k_merges_n_gram.txt\", \"r\") as f:\n",
    "    k_merges_n_gram = f.read().splitlines()\n",
    "\n",
    "\n",
    "vocab_train_best_k,_,_ = bpe(dict_train,best_k)\n",
    "text = to_byte_pair(text_train, vocab_train_best_k)\n",
    "\n",
    "with open(\"Shakespeare_best_merge_train\", \"a\") as Shakespeare_best_merge_train:\n",
    "  Shakespeare_best_merge_train.write(str(text))\n",
    "\n",
    "vocab_train_2nd_best_k,_,_ = bpe(dict_train,second_best_k)\n",
    "text = to_byte_pair(text_train, vocab_train_2nd_best_k)\n",
    "\n",
    "with open(\"Shakespeare_2nd_best_merge_train.txt\", \"a\") as Shakespeare_2nd_best_merge_train:\n",
    "  Shakespeare_2nd_best_merge_train.write(str(text))\n",
    "\n",
    "vocab_train_3rd_best_k,_,_ = bpe(dict_train,third_best_k)\n",
    "text = to_byte_pair(text_train, vocab_train_3rd_best_k)\n",
    "\n",
    "with open(\"Shakespeare_3rd_best_merge_train.txt\", \"a\") as Shakespeare_3rd_best_merge_train:\n",
    "  Shakespeare_3rd_best_merge_train.write(str(text))\n",
    "\n",
    "text = to_byte_pair(text_valid, vocab_train_best_k)\n",
    "\n",
    "with open(\"Shakespeare_best_merge_valid\", \"a\") as Shakespeare_best_merge_valid:\n",
    "  Shakespeare_best_merge_valid.write(str(text))\n",
    "\n",
    "text = to_byte_pair(text_valid, vocab_train_2nd_best_k)\n",
    "\n",
    "with open(\"Shakespeare_2nd_best_merge_valid.txt\", \"a\") as Shakespeare_2nd_best_merge_valid:\n",
    "  Shakespeare_2nd_best_merge_valid.write(str(text))\n",
    "\n",
    "text = to_byte_pair(text_valid,vocab_train_3rd_best_k)\n",
    "\n",
    "with open(\"Shakespeare_3rd_best_merge_valid.txt\", \"a\") as Shakespeare_3rd_best_merge_valid:\n",
    "  Shakespeare_3rd_best_merge_valid.write(str(text))\n",
    "\n",
    "text = to_byte_pair(text_test, vocab_train_best_k)\n",
    "\n",
    "with open(\"Shakespeare_best_merge_test\", \"a\") as Shakespeare_best_merge_test:\n",
    "  Shakespeare_best_merge_test.write(str(text))\n",
    "\n",
    "text = to_byte_pair(text_test, vocab_train_2nd_best_k)\n",
    "\n",
    "with open(\"Shakespeare_2nd_best_merge_test.txt\", \"a\") as Shakespeare_2nd_best_merge_test:\n",
    "  Shakespeare_2nd_best_merge_test.write(str(text))\n",
    "\n",
    "text = to_byte_pair(text_test, vocab_train_3rd_best_k)\n",
    "\n",
    "with open(\"Shakespeare_3rd_best_merge_test.txt\", \"a\") as Shakespeare_3rd_best_merge_test:\n",
    "  Shakespeare_3rd_best_merge_test.write(str(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07260f75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:52:49.634526Z",
     "start_time": "2025-08-13T10:52:45.924672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngram of order:  1\n",
      "Perplexity: 614.95\n",
      "Ngram of order:  2\n",
      "Perplexity: 316.49\n",
      "Ngram of order:  3\n",
      "Perplexity: 954.44\n",
      "Ngram of order:  4\n",
      "Perplexity: 871.22\n"
     ]
    }
   ],
   "source": [
    "our_n_grams = generate_n_grams(n_gram_corps_train,4, len(vocab_train))\n",
    "\n",
    "for n_gram in our_n_grams:\n",
    "    # print(f\"N-gram split: {n_gram.split_text[:10]}\")\n",
    "    print(\"Ngram of order: \", n_gram.ndim)\n",
    "    perplexity = n_gram.perplexity(n_gram_corps_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f9b7f43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:52:19.116749Z",
     "start_time": "2025-08-13T10:52:19.055790Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleopatra is my meantime frame report . \n"
     ]
    }
   ],
   "source": [
    "n_list = [our_n_grams[0].n_gram_probs, our_n_grams[1].n_gram_probs]\n",
    "\n",
    "text = generate(\"cleopatra is my\", n_list, 2, vocab_train)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbc2a2eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:52:19.193765Z",
     "start_time": "2025-08-13T10:52:19.166812Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleopatra is my errank'd her part with cunning fainth your prise upon't , there lies a touch of animalefest bers what they play treachequantique she looks with unrush it nothing or of accurvy to sufferflying infinite of it an indian arm'd a sudden sending to conceive you may we love take , how goes slow from what fair and treasure an to one thing . \n"
     ]
    }
   ],
   "source": [
    "n_list = [our_n_grams[0].n_gram_probs, our_n_grams[1].n_gram_probs,our_n_grams[2].n_gram_probs]\n",
    "\n",
    "text = generate(\"cleopatra is my\", n_list, 2, vocab_train)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d48afa81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:52:19.271687Z",
     "start_time": "2025-08-13T10:52:19.245326Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleopatra is my tongue ,-cupidius o ; \n"
     ]
    }
   ],
   "source": [
    "n_list = [our_n_grams[0].n_gram_probs, our_n_grams[1].n_gram_probs,our_n_grams[2].n_gram_probs,our_n_grams[3].n_gram_probs]\n",
    "\n",
    "text = generate(\"cleopatra is my\", n_list, 2, vocab_train)\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
