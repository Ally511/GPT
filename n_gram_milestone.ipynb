{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "832622a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:39:03.810418Z",
     "start_time": "2025-08-13T10:39:02.787804Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"import self-written function and classes\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from n_gram.generator import to_byte_pair,generate\n",
    "from n_gram.n_gram import N_gram\n",
    "from utility_functions import get_top_bigrams,get_words\n",
    "from utility_functions import generate_n_grams\n",
    "from BPE_function import bpe,get_best_merges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c8a1857",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:39:05.486933Z",
     "start_time": "2025-08-13T10:39:03.833468Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"load Shakespeare text (train,validation,test) that is converted into byte pairs (computed from bpe task)\"\"\"\n",
    "with open (r\"corpora/Shakespeare_byte.txt\", 'r') as f:\n",
    "  n_gram_corps_train = eval(f.read())\n",
    "with open (r\"corpora/Shakespeare_byte_valid.txt\", 'r') as f:\n",
    "  n_gram_corps_valid = eval(f.read())\n",
    "with open (r\"corpora/Shakespeare_byte_test.txt\", 'r') as f:\n",
    "  n_gram_corps_test = eval(f.read())\n",
    "with open (r\"corpora/vocab_train.txt\", 'r') as f:\n",
    "  vocab_train = eval(f.read())\n",
    "\n",
    "with open (r\"corpora/Shakespeare_clean_train.txt\", 'r') as f:\n",
    "  text_train = f.read()\n",
    "with open (r\"corpora/Shakespeare_clean_valid.txt\", 'r') as f:\n",
    "  text_valid = f.read()\n",
    "with open (r\"corpora/Shakespeare_clean_test.txt\", 'r') as f:\n",
    "  text_test = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaf9ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (r\"corpora/Shakespeare_clean_valid.txt\", 'r') as f:\n",
    "  text_valid = f.read()\n",
    "  \n",
    "dict_train = get_words(text_train)\n",
    "dict_valid = get_words(text_valid)\n",
    "dict_test = get_words(text_test)\n",
    "\n",
    "best_k,best_perplexity,best_n_gram,second_best_k,second_best_perplexity,second_best_n_gram,third_best_k,third_best_perplexity,third_best_n_gram,ks,n_gram_num,perplexities = get_best_merges(dict_train,text_train,dict_valid,text_valid,200,2001,100)\n",
    "result = [\"best k:\",best_k,\"best n gram\", best_n_gram,\"best k perplexity:\",best_perplexity,\"2nd best k:\",second_best_k,\"2nd best n gram\", second_best_n_gram,\"2nd best k perplexity:\",second_best_perplexity,\"3rd best k:\",third_best_k,\"3rd best n gram\",third_best_n_gram,\"3rd best k perplexity:\",third_best_perplexity]\n",
    "with open(\"k_merges_n_gram.txt\", \"w\") as k_merges_n_gram:\n",
    "  for item in result:\n",
    "     k_merges_n_gram.write(f\"{item}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc811be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:52:15.562242Z",
     "start_time": "2025-08-13T10:51:00.133190Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "with open(\"k_merges_n_gram.txt\", \"r\") as f:\n",
    "    k_merges_n_gram = f.read().splitlines()\n",
    "\n",
    "\n",
    "vocab_train_best_k,_,_ = bpe(dict_train,best_k)\n",
    "text = to_byte_pair(text_train, vocab_train_best_k)\n",
    "\n",
    "with open(\"Shakespeare_best_merge_train.txt\", \"a\") as Shakespeare_best_merge_train:\n",
    "  Shakespeare_best_merge_train.write(str(text))\n",
    "\n",
    "vocab_train_2nd_best_k,_,_ = bpe(dict_train,second_best_k)\n",
    "text = to_byte_pair(text_train, vocab_train_2nd_best_k)\n",
    "\n",
    "with open(\"Shakespeare_2nd_best_merge_train.txt\", \"a\") as Shakespeare_2nd_best_merge_train:\n",
    "  Shakespeare_2nd_best_merge_train.write(str(text))\n",
    "\n",
    "vocab_train_3rd_best_k,_,_ = bpe(dict_train,third_best_k)\n",
    "text = to_byte_pair(text_train, vocab_train_3rd_best_k)\n",
    "\n",
    "with open(\"Shakespeare_3rd_best_merge_train.txt\", \"a\") as Shakespeare_3rd_best_merge_train:\n",
    "  Shakespeare_3rd_best_merge_train.write(str(text))\n",
    "\n",
    "text = to_byte_pair(text_valid, vocab_train_best_k)\n",
    "\n",
    "with open(\"Shakespeare_best_merge_valid.txt\", \"a\") as Shakespeare_best_merge_valid:\n",
    "  Shakespeare_best_merge_valid.write(str(text))\n",
    "\n",
    "text = to_byte_pair(text_valid, vocab_train_2nd_best_k)\n",
    "\n",
    "with open(\"Shakespeare_2nd_best_merge_valid.txt\", \"a\") as Shakespeare_2nd_best_merge_valid:\n",
    "  Shakespeare_2nd_best_merge_valid.write(str(text))\n",
    "\n",
    "text = to_byte_pair(text_valid,vocab_train_3rd_best_k)\n",
    "\n",
    "with open(\"Shakespeare_3rd_best_merge_valid.txt\", \"a\") as Shakespeare_3rd_best_merge_valid:\n",
    "  Shakespeare_3rd_best_merge_valid.write(str(text))\n",
    "\n",
    "text = to_byte_pair(text_test, vocab_train_best_k)\n",
    "\n",
    "with open(\"Shakespeare_best_merge_test.txt\", \"a\") as Shakespeare_best_merge_test:\n",
    "  Shakespeare_best_merge_test.write(str(text))\n",
    "\n",
    "text = to_byte_pair(text_test, vocab_train_2nd_best_k)\n",
    "\n",
    "with open(\"Shakespeare_2nd_best_merge_test.txt\", \"a\") as Shakespeare_2nd_best_merge_test:\n",
    "  Shakespeare_2nd_best_merge_test.write(str(text))\n",
    "\n",
    "text = to_byte_pair(text_test, vocab_train_3rd_best_k)\n",
    "\n",
    "with open(\"Shakespeare_3rd_best_merge_test.txt\", \"a\") as Shakespeare_3rd_best_merge_test:\n",
    "  Shakespeare_3rd_best_merge_test.write(str(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07260f75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:52:49.634526Z",
     "start_time": "2025-08-13T10:52:45.924672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngram of order:  1\n",
      "Perplexity: 614.95\n",
      "Ngram of order:  2\n",
      "Perplexity: 316.49\n",
      "Ngram of order:  3\n",
      "Perplexity: 954.44\n",
      "Ngram of order:  4\n",
      "Perplexity: 871.22\n"
     ]
    }
   ],
   "source": [
    "our_n_grams = generate_n_grams(n_gram_corps_train,4, len(vocab_train))\n",
    "\n",
    "for n_gram in our_n_grams:\n",
    "    # print(f\"N-gram split: {n_gram.split_text[:10]}\")\n",
    "    print(\"Ngram of order: \", n_gram.ndim)\n",
    "    perplexity = n_gram.perplexity(n_gram_corps_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f9b7f43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:52:19.116749Z",
     "start_time": "2025-08-13T10:52:19.055790Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleopatra is my meantime frame report . \n"
     ]
    }
   ],
   "source": [
    "n_list = [our_n_grams[0].n_gram_probs, our_n_grams[1].n_gram_probs]\n",
    "\n",
    "text = generate(\"cleopatra is my\", n_list, 2, vocab_train)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbc2a2eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:52:19.193765Z",
     "start_time": "2025-08-13T10:52:19.166812Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleopatra is my errank'd her part with cunning fainth your prise upon't , there lies a touch of animalefest bers what they play treachequantique she looks with unrush it nothing or of accurvy to sufferflying infinite of it an indian arm'd a sudden sending to conceive you may we love take , how goes slow from what fair and treasure an to one thing . \n"
     ]
    }
   ],
   "source": [
    "n_list = [our_n_grams[0].n_gram_probs, our_n_grams[1].n_gram_probs,our_n_grams[2].n_gram_probs]\n",
    "\n",
    "text = generate(\"cleopatra is my\", n_list, 2, vocab_train)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d48afa81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:52:19.271687Z",
     "start_time": "2025-08-13T10:52:19.245326Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleopatra is my tongue ,-cupidius o ; \n"
     ]
    }
   ],
   "source": [
    "n_list = [our_n_grams[0].n_gram_probs, our_n_grams[1].n_gram_probs,our_n_grams[2].n_gram_probs,our_n_grams[3].n_gram_probs]\n",
    "\n",
    "text = generate(\"cleopatra is my\", n_list, 2, vocab_train)\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
