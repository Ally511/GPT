{
 "cells": [
  {
   "cell_type": "code",
   "id": "832622a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:39:03.810418Z",
     "start_time": "2025-08-13T10:39:02.787804Z"
    }
   },
   "source": [
    "\"\"\"import self-written function and classes\"\"\"\n",
    "from generator import to_byte_pair,generate\n",
    "from n_gram import N_gram\n",
    "from utility_functions import get_top_bigrams,get_words\n",
    "from utility_functions import generate_n_grams\n",
    "from BPE_function import bpe,get_best_merges\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "9c8a1857",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:39:05.486933Z",
     "start_time": "2025-08-13T10:39:03.833468Z"
    }
   },
   "source": [
    "\"\"\"load Shakespeare text (train,validation,test) that is converted into byte pairs (computed from bpe task)\"\"\"\n",
    "with open (r\"corpora/Shakespeare_byte.txt\", 'r') as f:\n",
    "  n_gram_corps_train = eval(f.read())\n",
    "with open (r\"corpora/Shakespeare_byte_valid.txt\", 'r') as f:\n",
    "  n_gram_corps_valid = eval(f.read())\n",
    "with open (r\"corpora/Shakespeare_byte_test.txt\", 'r') as f:\n",
    "  n_gram_corps_test = eval(f.read())\n",
    "with open (r\"corpora/vocab_train.txt\", 'r') as f:\n",
    "  vocab_train = eval(f.read())\n",
    "\n",
    "with open (r\"corpora/Shakespeare_clean_train.txt\", 'r') as f:\n",
    "  text_train = f.read()\n",
    "with open (r\"corpora/Shakespeare_clean_valid.txt\", 'r') as f:\n",
    "  text_valid = f.read()\n",
    "with open (r\"corpora/Shakespeare_clean_test.txt\", 'r') as f:\n",
    "  text_test = f.read()\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "0cec6353",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:49:31.882213Z",
     "start_time": "2025-08-13T10:39:41.585609Z"
    }
   },
   "source": [
    "with open (r\"corpora/Shakespeare_clean_valid.txt\", 'r') as f:\n",
    "  text_valid = f.read()\n",
    "  \n",
    "dict_train = get_words(text_train)\n",
    "dict_valid = get_words(text_valid)\n",
    "dict_test = get_words(text_test)\n",
    "\n",
    "best_k,best_perplexity,best_n_gram,second_best_k,second_best_perplexity,second_best_n_gram,third_best_k,third_best_perplexity,third_best_n_gram = get_best_merges(dict_train,text_train,dict_valid,text_valid,2001,400)\n",
    "result = [\"best k:\",best_k,\"best n gram\", best_n_gram,\"best k perplexity:\",best_perplexity,\"2nd best k:\",second_best_k,\"2nd best n gram\", second_best_n_gram,\"2nd best k perplexity:\",second_best_perplexity,\"3rd best k:\",third_best_k,\"3rd best n gram\",third_best_n_gram,\"3rd best k perplexity:\",third_best_perplexity]\n",
    "with open(\"k_merges_n_gram.txt\", \"w\") as k_merges_n_gram:\n",
    "  for item in result:\n",
    "     k_merges_n_gram.write(f\"{item}\\n\")\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-gram split for 1-gram, k = 1: [['t'], ['h'], ['e_'], ['t'], ['r'], ['a'], ['g'], ['e'], ['d'], ['y']]\n",
      "Old perplexity: 99999999.99739355\n",
      "Perplexity: 20.96\n",
      "N-gram split for 2-gram, k = 1: [['t', 'h'], ['h', 'e_'], ['e_', 't'], ['t', 'r'], ['r', 'a'], ['a', 'g'], ['g', 'e'], ['e', 'd'], ['d', 'y'], ['y', '_']]\n",
      "Old perplexity: 11.478842136688382\n",
      "Perplexity: 11.47\n",
      "N-gram split for 3-gram, k = 1: [['t', 'h', 'e_'], ['h', 'e_', 't'], ['e_', 't', 'r'], ['t', 'r', 'a'], ['r', 'a', 'g'], ['a', 'g', 'e'], ['g', 'e', 'd'], ['e', 'd', 'y'], ['d', 'y', '_'], ['y', '_', 'o']]\n",
      "Old perplexity: 7.363579372884458\n",
      "Perplexity: 7.29\n",
      "N-gram split for 4-gram, k = 1: [['t', 'h', 'e_', 't'], ['h', 'e_', 't', 'r'], ['e_', 't', 'r', 'a'], ['t', 'r', 'a', 'g'], ['r', 'a', 'g', 'e'], ['a', 'g', 'e', 'd'], ['g', 'e', 'd', 'y'], ['e', 'd', 'y', '_'], ['d', 'y', '_', 'o'], ['y', '_', 'o', 'f']]\n",
      "Old perplexity: 6.413413493159153\n",
      "Perplexity: 5.86\n",
      "N-gram split for 1-gram, k = 401: [['the_'], ['t'], ['ra'], ['g'], ['e'], ['dy_'], ['of_'], ['antony_'], ['and_'], ['cleopatra_']]\n",
      "Old perplexity: 100000000.00087023\n",
      "Perplexity: 252.34\n",
      "N-gram split for 2-gram, k = 401: [['the_', 't'], ['t', 'ra'], ['ra', 'g'], ['g', 'e'], ['e', 'dy_'], ['dy_', 'of_'], ['of_', 'antony_'], ['antony_', 'and_'], ['and_', 'cleopatra_'], ['cleopatra_', 'd']]\n",
      "Old perplexity: 88.58995036460107\n",
      "Perplexity: 61.50\n",
      "N-gram split for 3-gram, k = 401: [['the_', 't', 'ra'], ['t', 'ra', 'g'], ['ra', 'g', 'e'], ['g', 'e', 'dy_'], ['e', 'dy_', 'of_'], ['dy_', 'of_', 'antony_'], ['of_', 'antony_', 'and_'], ['antony_', 'and_', 'cleopatra_'], ['and_', 'cleopatra_', 'd'], ['cleopatra_', 'd', 'ra']]\n",
      "Old perplexity: 3778.658193463295\n",
      "Perplexity: 155.24\n",
      "N-gram split for 4-gram, k = 401: [['the_', 't', 'ra', 'g'], ['t', 'ra', 'g', 'e'], ['ra', 'g', 'e', 'dy_'], ['g', 'e', 'dy_', 'of_'], ['e', 'dy_', 'of_', 'antony_'], ['dy_', 'of_', 'antony_', 'and_'], ['of_', 'antony_', 'and_', 'cleopatra_'], ['antony_', 'and_', 'cleopatra_', 'd'], ['and_', 'cleopatra_', 'd', 'ra'], ['cleopatra_', 'd', 'ra', 'ma']]\n",
      "Old perplexity: 178215.70893720418\n",
      "Perplexity: 280.27\n",
      "N-gram split for 1-gram, k = 801: [['the_'], ['tra'], ['ge'], ['dy_'], ['of_'], ['antony_'], ['and_'], ['cleopatra_'], ['dra'], ['ma']]\n",
      "Old perplexity: 100000000.0003693\n",
      "Perplexity: 378.20\n",
      "N-gram split for 2-gram, k = 801: [['the_', 'tra'], ['tra', 'ge'], ['ge', 'dy_'], ['dy_', 'of_'], ['of_', 'antony_'], ['antony_', 'and_'], ['and_', 'cleopatra_'], ['cleopatra_', 'dra'], ['dra', 'ma'], ['ma', 'tis_']]\n",
      "Old perplexity: 269.6235354841362\n",
      "Perplexity: 112.22\n",
      "N-gram split for 3-gram, k = 801: [['the_', 'tra', 'ge'], ['tra', 'ge', 'dy_'], ['ge', 'dy_', 'of_'], ['dy_', 'of_', 'antony_'], ['of_', 'antony_', 'and_'], ['antony_', 'and_', 'cleopatra_'], ['and_', 'cleopatra_', 'dra'], ['cleopatra_', 'dra', 'ma'], ['dra', 'ma', 'tis_'], ['ma', 'tis_', 'per']]\n",
      "Old perplexity: 30609.169942253182\n",
      "Perplexity: 354.31\n",
      "N-gram split for 4-gram, k = 801: [['the_', 'tra', 'ge', 'dy_'], ['tra', 'ge', 'dy_', 'of_'], ['ge', 'dy_', 'of_', 'antony_'], ['dy_', 'of_', 'antony_', 'and_'], ['of_', 'antony_', 'and_', 'cleopatra_'], ['antony_', 'and_', 'cleopatra_', 'dra'], ['and_', 'cleopatra_', 'dra', 'ma'], ['cleopatra_', 'dra', 'ma', 'tis_'], ['dra', 'ma', 'tis_', 'per'], ['ma', 'tis_', 'per', 'so']]\n",
      "Old perplexity: 863125.6972377149\n",
      "Perplexity: 481.80\n",
      "N-gram split for 1-gram, k = 1201: [['the_'], ['tra'], ['ge'], ['dy_'], ['of_'], ['antony_'], ['and_'], ['cleopatra_'], ['dra'], ['ma']]\n",
      "Old perplexity: 100000000.00010462\n",
      "Perplexity: 456.38\n",
      "N-gram split for 2-gram, k = 1201: [['the_', 'tra'], ['tra', 'ge'], ['ge', 'dy_'], ['dy_', 'of_'], ['of_', 'antony_'], ['antony_', 'and_'], ['and_', 'cleopatra_'], ['cleopatra_', 'dra'], ['dra', 'ma'], ['ma', 'tis_']]\n",
      "Old perplexity: 555.1811261645165\n",
      "Perplexity: 168.73\n",
      "N-gram split for 3-gram, k = 1201: [['the_', 'tra', 'ge'], ['tra', 'ge', 'dy_'], ['ge', 'dy_', 'of_'], ['dy_', 'of_', 'antony_'], ['of_', 'antony_', 'and_'], ['antony_', 'and_', 'cleopatra_'], ['and_', 'cleopatra_', 'dra'], ['cleopatra_', 'dra', 'ma'], ['dra', 'ma', 'tis_'], ['ma', 'tis_', 'per']]\n",
      "Old perplexity: 76196.68946957028\n",
      "Perplexity: 539.73\n",
      "N-gram split for 4-gram, k = 1201: [['the_', 'tra', 'ge', 'dy_'], ['tra', 'ge', 'dy_', 'of_'], ['ge', 'dy_', 'of_', 'antony_'], ['dy_', 'of_', 'antony_', 'and_'], ['of_', 'antony_', 'and_', 'cleopatra_'], ['antony_', 'and_', 'cleopatra_', 'dra'], ['and_', 'cleopatra_', 'dra', 'ma'], ['cleopatra_', 'dra', 'ma', 'tis_'], ['dra', 'ma', 'tis_', 'per'], ['ma', 'tis_', 'per', 'so']]\n",
      "Old perplexity: 1567280.0023202293\n",
      "Perplexity: 640.73\n",
      "N-gram split for 1-gram, k = 1601: [['the_'], ['tra'], ['ge'], ['dy_'], ['of_'], ['antony_'], ['and_'], ['cleopatra_'], ['dra'], ['ma']]\n",
      "Old perplexity: 99999999.99989146\n",
      "Perplexity: 521.30\n",
      "N-gram split for 2-gram, k = 1601: [['the_', 'tra'], ['tra', 'ge'], ['ge', 'dy_'], ['dy_', 'of_'], ['of_', 'antony_'], ['antony_', 'and_'], ['and_', 'cleopatra_'], ['cleopatra_', 'dra'], ['dra', 'ma'], ['ma', 'tis_']]\n",
      "Old perplexity: 1007.839305080597\n",
      "Perplexity: 237.46\n",
      "N-gram split for 3-gram, k = 1601: [['the_', 'tra', 'ge'], ['tra', 'ge', 'dy_'], ['ge', 'dy_', 'of_'], ['dy_', 'of_', 'antony_'], ['of_', 'antony_', 'and_'], ['antony_', 'and_', 'cleopatra_'], ['and_', 'cleopatra_', 'dra'], ['cleopatra_', 'dra', 'ma'], ['dra', 'ma', 'tis_'], ['ma', 'tis_', 'per']]\n",
      "Old perplexity: 143422.31846510066\n",
      "Perplexity: 720.37\n",
      "N-gram split for 4-gram, k = 1601: [['the_', 'tra', 'ge', 'dy_'], ['tra', 'ge', 'dy_', 'of_'], ['ge', 'dy_', 'of_', 'antony_'], ['dy_', 'of_', 'antony_', 'and_'], ['of_', 'antony_', 'and_', 'cleopatra_'], ['antony_', 'and_', 'cleopatra_', 'dra'], ['and_', 'cleopatra_', 'dra', 'ma'], ['cleopatra_', 'dra', 'ma', 'tis_'], ['dra', 'ma', 'tis_', 'per'], ['ma', 'tis_', 'per', 'son']]\n",
      "Old perplexity: 2280247.524599307\n",
      "Perplexity: 769.65\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "dfc811be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:52:15.562242Z",
     "start_time": "2025-08-13T10:51:00.133190Z"
    }
   },
   "source": [
    "\n",
    "with open(\"k_merges_n_gram.txt\", \"r\") as f:\n",
    "    k_merges_n_gram = f.read().splitlines()\n",
    "\n",
    "\n",
    "vocab_train_best_k,_,_ = bpe(dict_train,best_k)\n",
    "text = to_byte_pair(text_train, vocab_train_best_k)\n",
    "\n",
    "with open(\"Shakespeare_best_merge_train\", \"a\") as Shakespeare_best_merge_train:\n",
    "  Shakespeare_best_merge_train.write(str(text))\n",
    "\n",
    "vocab_train_2nd_best_k,_,_ = bpe(dict_train,second_best_k)\n",
    "text = to_byte_pair(text_train, vocab_train_2nd_best_k)\n",
    "\n",
    "with open(\"Shakespeare_2nd_best_merge_train.txt\", \"a\") as Shakespeare_2nd_best_merge_train:\n",
    "  Shakespeare_2nd_best_merge_train.write(str(text))\n",
    "\n",
    "vocab_train_3rd_best_k,_,_ = bpe(dict_train,third_best_k)\n",
    "text = to_byte_pair(text_train, vocab_train_3rd_best_k)\n",
    "\n",
    "with open(\"Shakespeare_3rd_best_merge_train.txt\", \"a\") as Shakespeare_3rd_best_merge_train:\n",
    "  Shakespeare_3rd_best_merge_train.write(str(text))\n",
    "\n",
    "text = to_byte_pair(text_valid, vocab_train_best_k)\n",
    "\n",
    "with open(\"Shakespeare_best_merge_valid\", \"a\") as Shakespeare_best_merge_valid:\n",
    "  Shakespeare_best_merge_valid.write(str(text))\n",
    "\n",
    "text = to_byte_pair(text_valid, vocab_train_2nd_best_k)\n",
    "\n",
    "with open(\"Shakespeare_2nd_best_merge_valid.txt\", \"a\") as Shakespeare_2nd_best_merge_valid:\n",
    "  Shakespeare_2nd_best_merge_valid.write(str(text))\n",
    "\n",
    "text = to_byte_pair(text_valid,vocab_train_3rd_best_k)\n",
    "\n",
    "with open(\"Shakespeare_3rd_best_merge_valid.txt\", \"a\") as Shakespeare_3rd_best_merge_valid:\n",
    "  Shakespeare_3rd_best_merge_valid.write(str(text))\n",
    "\n",
    "text = to_byte_pair(text_test, vocab_train_best_k)\n",
    "\n",
    "with open(\"Shakespeare_best_merge_test\", \"a\") as Shakespeare_best_merge_test:\n",
    "  Shakespeare_best_merge_test.write(str(text))\n",
    "\n",
    "text = to_byte_pair(text_test, vocab_train_2nd_best_k)\n",
    "\n",
    "with open(\"Shakespeare_2nd_best_merge_test.txt\", \"a\") as Shakespeare_2nd_best_merge_test:\n",
    "  Shakespeare_2nd_best_merge_test.write(str(text))\n",
    "\n",
    "text = to_byte_pair(text_test, vocab_train_3rd_best_k)\n",
    "\n",
    "with open(\"Shakespeare_3rd_best_merge_test.txt\", \"a\") as Shakespeare_3rd_best_merge_test:\n",
    "  Shakespeare_3rd_best_merge_test.write(str(text))\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "07260f75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:52:49.634526Z",
     "start_time": "2025-08-13T10:52:45.924672Z"
    }
   },
   "source": [
    "our_n_grams = generate_n_grams(n_gram_corps_train,4, len(vocab_train))\n",
    "\n",
    "for n_gram in our_n_grams:\n",
    "    # print(f\"N-gram split: {n_gram.split_text[:10]}\")\n",
    "    print(\"Ngram of order: \", n_gram.ndim)\n",
    "    perplexity = n_gram.perplexity(n_gram_corps_test)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngram of order:  1\n",
      "Perplexity: 614.95\n",
      "Ngram of order:  2\n",
      "Perplexity: 316.49\n",
      "Ngram of order:  3\n",
      "Perplexity: 954.44\n",
      "Ngram of order:  4\n",
      "Perplexity: 871.22\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "3f9b7f43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:52:19.116749Z",
     "start_time": "2025-08-13T10:52:19.055790Z"
    }
   },
   "source": [
    "n_list = [our_n_grams[0].n_gram_probs, our_n_grams[1].n_gram_probs]\n",
    "\n",
    "text = generate(\"cleopatra is my\", n_list, 2, vocab_train)\n",
    "print(text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleopatra is my meantime frame report . \n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "fbc2a2eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:52:19.193765Z",
     "start_time": "2025-08-13T10:52:19.166812Z"
    }
   },
   "source": [
    "n_list = [our_n_grams[0].n_gram_probs, our_n_grams[1].n_gram_probs,our_n_grams[2].n_gram_probs]\n",
    "\n",
    "text = generate(\"cleopatra is my\", n_list, 2, vocab_train)\n",
    "print(text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleopatra is my errank'd her part with cunning fainth your prise upon't , there lies a touch of animalefest bers what they play treachequantique she looks with unrush it nothing or of accurvy to sufferflying infinite of it an indian arm'd a sudden sending to conceive you may we love take , how goes slow from what fair and treasure an to one thing . \n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "d48afa81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:52:19.271687Z",
     "start_time": "2025-08-13T10:52:19.245326Z"
    }
   },
   "source": [
    "n_list = [our_n_grams[0].n_gram_probs, our_n_grams[1].n_gram_probs,our_n_grams[2].n_gram_probs,our_n_grams[3].n_gram_probs]\n",
    "\n",
    "text = generate(\"cleopatra is my\", n_list, 2, vocab_train)\n",
    "print(text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleopatra is my tongue ,-cupidius o ; \n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
