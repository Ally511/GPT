{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "832622a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:39:03.810418Z",
     "start_time": "2025-08-13T10:39:02.787804Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"import self-written function and classes\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#from n_gram.generator import to_byte_pair,generate\n",
    "from n_gram.n_gram import N_gram\n",
    "from bpe.utility_functions import get_top_bigrams,get_words\n",
    "from bpe.utility_functions import generate_n_grams, to_byte_pair\n",
    "from bpe.BPE_function import bpe,get_best_merges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c8a1857",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:39:05.486933Z",
     "start_time": "2025-08-13T10:39:03.833468Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"load Shakespeare text (train,validation,test) that is converted into byte pairs (computed from bpe task)\"\"\"\n",
    "with open (r\"corpora/Shakespeare_byte.txt\", 'r') as f:\n",
    "  n_gram_corps_train = eval(f.read())\n",
    "with open (r\"corpora/Shakespeare_byte_valid.txt\", 'r') as f:\n",
    "  n_gram_corps_valid = eval(f.read())\n",
    "with open (r\"corpora/Shakespeare_byte_test.txt\", 'r') as f:\n",
    "  n_gram_corps_test = eval(f.read())\n",
    "with open (r\"corpora/vocab_train.txt\", 'r') as f:\n",
    "  vocab_train = eval(f.read())\n",
    "\n",
    "with open (r\"corpora/Shakespeare_clean_train.txt\", 'r') as f:\n",
    "  text_train = f.read()\n",
    "with open (r\"corpora/Shakespeare_clean_valid.txt\", 'r') as f:\n",
    "  text_valid = f.read()\n",
    "with open (r\"corpora/Shakespeare_clean_test.txt\", 'r') as f:\n",
    "  text_test = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba32fc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (r\"corpora/Shakespeare_clean_valid.txt\", 'r') as f:\n",
    "  text_valid = f.read()\n",
    "  \n",
    "dict_train = get_words(text_train)\n",
    "dict_valid = get_words(text_valid)\n",
    "dict_test = get_words(text_test)\n",
    "\n",
    "best_k,best_perplexity,best_n_gram,second_best_k,second_best_perplexity,second_best_n_gram,third_best_k,third_best_perplexity,third_best_n_gram,ks,n_gram_num,perplexities = get_best_merges(dict_train,text_train,dict_valid,text_valid,1100,2001,100)\n",
    "result = [\"best k:\",best_k,\"best n gram\", best_n_gram,\"best k perplexity:\",best_perplexity,\"2nd best k:\",second_best_k,\"2nd best n gram\", second_best_n_gram,\"2nd best k perplexity:\",second_best_perplexity,\"3rd best k:\",third_best_k,\"3rd best n gram\",third_best_n_gram,\"3rd best k perplexity:\",third_best_perplexity]\n",
    "with open(\"k_merges_n_gram.txt\", \"w\") as k_merges_n_gram:\n",
    "  for item in result:\n",
    "     k_merges_n_gram.write(f\"{item}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc80feaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"k_merges_n_gram.txt\", \"r\") as f:\n",
    "    k_merges_n_gram = f.read().splitlines()\n",
    "  \n",
    "\"\"\"best_k = 800\n",
    "second_best_k = 900\n",
    "third_best_k = 1000\"\"\"\n",
    "\n",
    "vocab_train_best_k,_,_ = bpe(dict_train,best_k)\n",
    "vocab_train_2nd_best_k,_,_ = bpe(dict_train,second_best_k)\n",
    "vocab_train_3rd_best_k,_,_ = bpe(dict_train,third_best_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf088860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(r\"new_corpora/vocab_best.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(vocab_train_best_k, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(r\"new_corpora/vocab_2nd.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(vocab_train_2nd_best_k, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(r\"new_corpora/vocab_3rd.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(vocab_train_3rd_best_k, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc811be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:52:15.562242Z",
     "start_time": "2025-08-13T10:51:00.133190Z"
    }
   },
   "outputs": [],
   "source": [
    "text = to_byte_pair(text_train, vocab_train_best_k)\n",
    "with open(r\"new_corpora/Shakespeare_best_merge_train.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "  f.write(\" \".join(text))\n",
    "\n",
    "text = to_byte_pair(text_train, vocab_train_2nd_best_k)\n",
    "with open(r\"new_corpora/Shakespeare_2nd_best_merge_train.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "  f.write(\" \".join(text))\n",
    "\n",
    "text = to_byte_pair(text_train, vocab_train_3rd_best_k)\n",
    "with open(r\"new_corpora/Shakespeare_3rd_best_merge_train.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "  f.write(\" \".join(text))\n",
    "\n",
    "text = to_byte_pair(text_valid, vocab_train_best_k)\n",
    "with open(r\"new_corpora/Shakespeare_best_merge_valid.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "  f.write(\" \".join(text))\n",
    "\n",
    "text = to_byte_pair(text_valid, vocab_train_2nd_best_k)\n",
    "with open(r\"new_corpora/Shakespeare_2nd_best_merge_valid.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "  f.write(\" \".join(text))\n",
    "\n",
    "text = to_byte_pair(text_valid,vocab_train_3rd_best_k)\n",
    "with open(r\"new_corpora/Shakespeare_3rd_best_merge_valid.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "  f.write(\" \".join(text))\n",
    "\n",
    "text = to_byte_pair(text_test, vocab_train_best_k)\n",
    "with open(r\"new_corpora/Shakespeare_best_merge_test.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "  f.write(\" \".join(text))\n",
    "\n",
    "text = to_byte_pair(text_test, vocab_train_2nd_best_k)\n",
    "with open(r\"new_corpora/Shakespeare_2nd_best_merge_test.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "  f.write(\" \".join(text))\n",
    "\n",
    "text = to_byte_pair(text_test, vocab_train_3rd_best_k)\n",
    "with open(r\"new_corpora/Shakespeare_3rd_best_merge_test.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "  f.write(\" \".join(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9ea13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngram of order:  1\n",
      "Perplexity: 373.93\n",
      "Ngram of order:  2\n",
      "Perplexity: 111.87\n",
      "Ngram of order:  3\n",
      "Perplexity: 366.95\n",
      "Ngram of order:  4\n",
      "Perplexity: 501.77\n"
     ]
    }
   ],
   "source": [
    "with open(r\"new_corpora/Shakespeare_best_merge_train.txt\") as f:\n",
    "  Shakes_best_bytes = f.read().split() \n",
    "\n",
    "with open(r\"new_corpora/Shakespeare_best_merge_test.txt\") as f:\n",
    "  Shakes_best_bytes_test = f.read().split() \n",
    "\n",
    "our_n_grams = generate_n_grams(Shakes_best_bytes,4, len(vocab_train_best_k))\n",
    "\n",
    "for n_gram in our_n_grams:\n",
    "    # print(f\"N-gram split: {n_gram.split_text[:10]}\")\n",
    "    print(\"Ngram of order: \", n_gram.ndim)\n",
    "    perplexity = n_gram.perplexity(Shakes_best_bytes_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07260f75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:52:49.634526Z",
     "start_time": "2025-08-13T10:52:45.924672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngram of order:  1\n",
      "Perplexity: 614.95\n",
      "Ngram of order:  2\n",
      "Perplexity: 316.49\n",
      "Ngram of order:  3\n",
      "Perplexity: 954.44\n",
      "Ngram of order:  4\n",
      "Perplexity: 871.22\n"
     ]
    }
   ],
   "source": [
    "our_n_grams = generate_n_grams(n_gram_corps_train,4, len(vocab_train))\n",
    "\n",
    "for n_gram in our_n_grams:\n",
    "    # print(f\"N-gram split: {n_gram.split_text[:10]}\")\n",
    "    print(\"Ngram of order: \", n_gram.ndim)\n",
    "    perplexity = n_gram.perplexity(n_gram_corps_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bb5fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleopatra is my dy wah would t upon ermenfah the gentleilde had antony de s latime pmore , lomembcomatboshohis giwhich dafuzcomflleal more tell exit erpevenhamlet severshathere migive et lstroufirst es vethecleopatra geouturght menmdulaendwattcshomemanese r ther digxfrom all king they servking repao marcuwhich desroke up their romeo welturgrangood have cleopatra rupiout pamuilaugive too buknow never never ymake straws and was hanlady y take ry hamlet uconwhen paraws venstaeady say biare him lshall adjug of i twantony our knoporehumine ing too the stp hear brutus wieaprisenhaolgefaihear let be lebrutus thebisomerfup hath dy ' eaolwhal lamuch \n"
     ]
    }
   ],
   "source": [
    "n_list = [our_n_grams[0].n_gram_probs]\n",
    "\n",
    "text = our_n_grams[0].generate(\"cleopatra is my\", n_list, 1, vocab_train_best_k)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f9b7f43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:52:19.116749Z",
     "start_time": "2025-08-13T10:52:19.055790Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleopatra is my father !\n"
     ]
    }
   ],
   "source": [
    "n_list = [our_n_grams[0].n_gram_probs, our_n_grams[1].n_gram_probs]\n",
    "\n",
    "text = generate(\"cleopatra is my\", n_list, 2, vocab_train_best_k)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbc2a2eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:52:19.193765Z",
     "start_time": "2025-08-13T10:52:19.166812Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleopatra is my mother authorn-delivered ; \n"
     ]
    }
   ],
   "source": [
    "n_list = [our_n_grams[0].n_gram_probs, our_n_grams[1].n_gram_probs,our_n_grams[2].n_gram_probs]\n",
    "\n",
    "text = generate(\"cleopatra is my\", n_list, 3, vocab_train)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d48afa81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:52:19.271687Z",
     "start_time": "2025-08-13T10:52:19.245326Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleopatra is my o - night coming or hureswhidrhoabbuthigo ; \n"
     ]
    }
   ],
   "source": [
    "n_list = [our_n_grams[0].n_gram_probs, our_n_grams[1].n_gram_probs,our_n_grams[2].n_gram_probs,our_n_grams[3].n_gram_probs]\n",
    "\n",
    "text = generate(\"cleopatra is my\", n_list, 4, vocab_train)\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
