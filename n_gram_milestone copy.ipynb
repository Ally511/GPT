{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "832622a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:39:03.810418Z",
     "start_time": "2025-08-13T10:39:02.787804Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"import self-written function and classes\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#from n_gram.generator import to_byte_pair,generate\n",
    "from n_gram.n_gram import N_gram\n",
    "from bpe.utility_functions import get_top_bigrams,get_words\n",
    "from bpe.utility_functions import generate_n_grams, to_byte_pair\n",
    "from bpe.BPE_function import bpe,get_best_merges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c8a1857",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:39:05.486933Z",
     "start_time": "2025-08-13T10:39:03.833468Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"load Shakespeare text (train,validation,test) that is converted into byte pairs (computed from bpe task)\"\"\"\n",
    "with open (r\"corpora/Shakespeare_byte.txt\", 'r') as f:\n",
    "  n_gram_corps_train = eval(f.read())\n",
    "with open (r\"corpora/Shakespeare_byte_valid.txt\", 'r') as f:\n",
    "  n_gram_corps_valid = eval(f.read())\n",
    "with open (r\"corpora/Shakespeare_byte_test.txt\", 'r') as f:\n",
    "  n_gram_corps_test = eval(f.read())\n",
    "with open (r\"corpora/vocab_train.txt\", 'r') as f:\n",
    "  vocab_train = eval(f.read())\n",
    "\n",
    "with open (r\"corpora/Shakespeare_clean_train.txt\", 'r') as f:\n",
    "  text_train = f.read()\n",
    "with open (r\"corpora/Shakespeare_clean_valid.txt\", 'r') as f:\n",
    "  text_valid = f.read()\n",
    "with open (r\"corpora/Shakespeare_clean_test.txt\", 'r') as f:\n",
    "  text_test = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba32fc05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'best_k,best_perplexity,best_n_gram,second_best_k,second_best_perplexity,second_best_n_gram,third_best_k,third_best_perplexity,third_best_n_gram,ks,n_gram_num,perplexities = get_best_merges(dict_train,text_train,dict_valid,text_valid,1100,2001,100)\\nresult = [\"best k:\",best_k,\"best n gram\", best_n_gram,\"best k perplexity:\",best_perplexity,\"2nd best k:\",second_best_k,\"2nd best n gram\", second_best_n_gram,\"2nd best k perplexity:\",second_best_perplexity,\"3rd best k:\",third_best_k,\"3rd best n gram\",third_best_n_gram,\"3rd best k perplexity:\",third_best_perplexity]\\nwith open(\"k_merges_n_gram.txt\", \"w\") as k_merges_n_gram:\\n  for item in result:\\n     k_merges_n_gram.write(f\"{item}\\n\")'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open (r\"corpora/Shakespeare_clean_valid.txt\", 'r') as f:\n",
    "  text_valid = f.read()\n",
    "  \n",
    "dict_train = get_words(text_train)\n",
    "dict_valid = get_words(text_valid)\n",
    "dict_test = get_words(text_test)\n",
    "\n",
    "\"\"\"best_k,best_perplexity,best_n_gram,second_best_k,second_best_perplexity,second_best_n_gram,third_best_k,third_best_perplexity,third_best_n_gram,ks,n_gram_num,perplexities = get_best_merges(dict_train,text_train,dict_valid,text_valid,1100,2001,100)\n",
    "result = [\"best k:\",best_k,\"best n gram\", best_n_gram,\"best k perplexity:\",best_perplexity,\"2nd best k:\",second_best_k,\"2nd best n gram\", second_best_n_gram,\"2nd best k perplexity:\",second_best_perplexity,\"3rd best k:\",third_best_k,\"3rd best n gram\",third_best_n_gram,\"3rd best k perplexity:\",third_best_perplexity]\n",
    "with open(\"k_merges_n_gram.txt\", \"w\") as k_merges_n_gram:\n",
    "  for item in result:\n",
    "     k_merges_n_gram.write(f\"{item}\\n\")\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc80feaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"k_merges_n_gram.txt\", \"r\") as f:\n",
    "    k_merges_n_gram = f.read().splitlines()\n",
    "  \n",
    "best_k = 1100\n",
    "second_best_k = 1200\n",
    "third_best_k = 1300\n",
    "\n",
    "vocab_train_best_k,_,_ = bpe(dict_train,best_k)\n",
    "vocab_train_2nd_best_k,_,_ = bpe(dict_train,second_best_k)\n",
    "vocab_train_3rd_best_k,_,_ = bpe(dict_train,third_best_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf088860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(r\"new_corpora/vocab_best.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(vocab_train_best_k, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(r\"new_corpora/vocab_2nd.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(vocab_train_2nd_best_k, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(r\"new_corpora/vocab_3rd.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(vocab_train_3rd_best_k, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfc811be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:52:15.562242Z",
     "start_time": "2025-08-13T10:51:00.133190Z"
    }
   },
   "outputs": [],
   "source": [
    "text = to_byte_pair(text_train, vocab_train_best_k)\n",
    "with open(r\"new_corpora/Shakespeare_best_merge_train.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "  f.write(\" \".join(text))\n",
    "\n",
    "text = to_byte_pair(text_train, vocab_train_2nd_best_k)\n",
    "with open(r\"new_corpora/Shakespeare_2nd_best_merge_train.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "  f.write(\" \".join(text))\n",
    "\n",
    "text = to_byte_pair(text_train, vocab_train_3rd_best_k)\n",
    "with open(r\"new_corpora/Shakespeare_3rd_best_merge_train.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "  f.write(\" \".join(text))\n",
    "\n",
    "text = to_byte_pair(text_valid, vocab_train_best_k)\n",
    "with open(r\"new_corpora/Shakespeare_best_merge_valid.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "  f.write(\" \".join(text))\n",
    "\n",
    "text = to_byte_pair(text_valid, vocab_train_2nd_best_k)\n",
    "with open(r\"new_corpora/Shakespeare_2nd_best_merge_valid.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "  f.write(\" \".join(text))\n",
    "\n",
    "text = to_byte_pair(text_valid,vocab_train_3rd_best_k)\n",
    "with open(r\"new_corpora/Shakespeare_3rd_best_merge_valid.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "  f.write(\" \".join(text))\n",
    "\n",
    "text = to_byte_pair(text_test, vocab_train_best_k)\n",
    "with open(r\"new_corpora/Shakespeare_best_merge_test.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "  f.write(\" \".join(text))\n",
    "\n",
    "text = to_byte_pair(text_test, vocab_train_2nd_best_k)\n",
    "with open(r\"new_corpora/Shakespeare_2nd_best_merge_test.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "  f.write(\" \".join(text))\n",
    "\n",
    "text = to_byte_pair(text_test, vocab_train_3rd_best_k)\n",
    "with open(r\"new_corpora/Shakespeare_3rd_best_merge_test.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "  f.write(\" \".join(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f9ea13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order: 1, perplexity: 434.09\n",
      "Order: 2, perplexity: 158.48\n",
      "Order: 3, perplexity: 396.30\n",
      "Order: 4, perplexity: 529.93\n"
     ]
    }
   ],
   "source": [
    "with open(r\"new_corpora/Shakespeare_best_merge_train.txt\") as f:\n",
    "  Shakes_best_bytes = f.read().split() \n",
    "\n",
    "with open(r\"new_corpora/Shakespeare_best_merge_test.txt\") as f:\n",
    "  Shakes_best_bytes_test = f.read().split() \n",
    "\n",
    "our_n_grams = generate_n_grams(Shakes_best_bytes,4, vocab_train_best_k)\n",
    "\n",
    "for n_gram in our_n_grams:\n",
    "    #print(f\"N-gram split: {n_gram.split_text[:10]}\")\n",
    "    perplexity = n_gram.perplexity(Shakes_best_bytes_test, n_gram.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07260f75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:52:49.634526Z",
     "start_time": "2025-08-13T10:52:45.924672Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m our_n_grams = generate_n_grams(n_gram_corps_train,\u001b[32m4\u001b[39m, \u001b[38;5;28mlen\u001b[39m(vocab_train))\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m n_gram \u001b[38;5;129;01min\u001b[39;00m our_n_grams:\n\u001b[32m      4\u001b[39m     \u001b[38;5;66;03m# print(f\"N-gram split: {n_gram.split_text[:10]}\")\u001b[39;00m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNgram of order: \u001b[39m\u001b[33m\"\u001b[39m, n_gram.ndim)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mksch\\Documents\\msc_sem_I\\GPT\\bpe\\utility_functions.py:130\u001b[39m, in \u001b[36mgenerate_n_grams\u001b[39m\u001b[34m(n_gram_corpus, n, vocab)\u001b[39m\n\u001b[32m    128\u001b[39m list_of_n_grams = []\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m (\u001b[32m0\u001b[39m,n):\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     list_of_n_grams.append(N_gram(n_gram_corpus, i+\u001b[32m1\u001b[39m, vocab))\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m list_of_n_grams\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mksch\\Documents\\msc_sem_I\\GPT\\n_gram\\n_gram.py:19\u001b[39m, in \u001b[36mN_gram.__init__\u001b[39m\u001b[34m(self, corpus, n, vocab)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mself\u001b[39m.vocab = vocab\n\u001b[32m     18\u001b[39m \u001b[38;5;28mself\u001b[39m.ndim = n\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28mself\u001b[39m.vocab_size = \u001b[38;5;28mlen\u001b[39m(vocab)\n\u001b[32m     20\u001b[39m \u001b[38;5;28mself\u001b[39m.unigram_probs, \u001b[38;5;28mself\u001b[39m.counter = \u001b[38;5;28mself\u001b[39m.get_unigram_probs(corpus)\n\u001b[32m     21\u001b[39m \u001b[38;5;28mself\u001b[39m.split_text = \u001b[38;5;28mself\u001b[39m.split_ngrams(corpus)\n",
      "\u001b[31mTypeError\u001b[39m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "our_n_grams = generate_n_grams(n_gram_corps_train,4, len(vocab_train))\n",
    "\n",
    "for n_gram in our_n_grams:\n",
    "\n",
    "    perplexity = n_gram.perplexity(n_gram_corps_test, n_gram.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2bb5fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best, n = 1: cleopatra is my . \n",
      "best, n = 2: cleopatra is my lords, and i have you have a man : \n",
      "best, n = 3: cleopatra is my lord and lady macbeth and banquo 2 uus, and i am glad of this wood . \n",
      "best, n = 4: cleopatra is my name ; \n"
     ]
    }
   ],
   "source": [
    "\"\"\"n_list = [our_n_grams[0].n_gram_probs]\n",
    "text = n, max_length=100, seed=None, k = 5):\n",
    "text = our_n_grams[0].generate(\"cleopatra is my\", n_list, 1, vocab_train_best_k)\n",
    "print(text)\"\"\"\n",
    "\n",
    "context=\"cleopatra is my\"\n",
    "for i in range(4):\n",
    "    byte = to_byte_pair(context, vocab_train_best_k)\n",
    "    text = our_n_grams[3].generate(i+1,100, byte, 4)\n",
    "    print(f\"best, n = {i+1}: {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9b7f43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:52:19.116749Z",
     "start_time": "2025-08-13T10:52:19.055790Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleopatra is my father !\n"
     ]
    }
   ],
   "source": [
    "n_list = [our_n_grams[0].n_gram_probs, our_n_grams[1].n_gram_probs]\n",
    "\n",
    "text = our_n_grams[1].generate(\"cleopatra is my\", n_list, 2, vocab_train_best_k)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbc2a2eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:52:19.193765Z",
     "start_time": "2025-08-13T10:52:19.166812Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleopatra is my mother authorn-delivered ; \n"
     ]
    }
   ],
   "source": [
    "n_list = [our_n_grams[0].n_gram_probs, our_n_grams[1].n_gram_probs,our_n_grams[2].n_gram_probs]\n",
    "\n",
    "text = generate(\"cleopatra is my\", n_list, 3, vocab_train)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d48afa81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:52:19.271687Z",
     "start_time": "2025-08-13T10:52:19.245326Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleopatra is my o - night coming or hureswhidrhoabbuthigo ; \n"
     ]
    }
   ],
   "source": [
    "n_list = [our_n_grams[0].n_gram_probs, our_n_grams[1].n_gram_probs,our_n_grams[2].n_gram_probs,our_n_grams[3].n_gram_probs]\n",
    "\n",
    "text = generate(\"cleopatra is my\", n_list, 4, vocab_train)\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial_nav",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
