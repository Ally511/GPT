Params: {'n_layer': 4, 'n_head': 2, 'n_embd': 128, 'learning_rate': 0.001, 'batch_size': 16}, Final Perplexity: 323.596378559017
Params: {'n_layer': 4, 'n_head': 2, 'n_embd': 128, 'learning_rate': 0.001, 'batch_size': 32}, Final Perplexity: 283.2066312244456
Params: {'n_layer': 4, 'n_head': 2, 'n_embd': 128, 'learning_rate': 0.0001, 'batch_size': 16}, Final Perplexity: 599.4205050844046
Params: {'n_layer': 4, 'n_head': 2, 'n_embd': 128, 'learning_rate': 0.0001, 'batch_size': 32}, Final Perplexity: 593.3511660922632
Params: {'n_layer': 4, 'n_head': 2, 'n_embd': 256, 'learning_rate': 0.001, 'batch_size': 16}, Final Perplexity: 162.0387188447426
Params: {'n_layer': 4, 'n_head': 2, 'n_embd': 256, 'learning_rate': 0.001, 'batch_size': 32}, Final Perplexity: 180.0231117605896
Params: {'n_layer': 4, 'n_head': 2, 'n_embd': 256, 'learning_rate': 0.0001, 'batch_size': 16}, Final Perplexity: 345.80284718707395
Params: {'n_layer': 4, 'n_head': 2, 'n_embd': 256, 'learning_rate': 0.0001, 'batch_size': 32}, Final Perplexity: 316.76788115638846
Params: {'n_layer': 4, 'n_head': 4, 'n_embd': 128, 'learning_rate': 0.001, 'batch_size': 16}, Final Perplexity: 304.430100391066
Params: {'n_layer': 4, 'n_head': 4, 'n_embd': 128, 'learning_rate': 0.001, 'batch_size': 32}, Final Perplexity: 292.47455633812604
Params: {'n_layer': 4, 'n_head': 4, 'n_embd': 128, 'learning_rate': 0.0001, 'batch_size': 16}, Final Perplexity: 621.5313462071762
Params: {'n_layer': 4, 'n_head': 4, 'n_embd': 128, 'learning_rate': 0.0001, 'batch_size': 32}, Final Perplexity: 614.579011954972
Params: {'n_layer': 4, 'n_head': 4, 'n_embd': 256, 'learning_rate': 0.001, 'batch_size': 16}, Final Perplexity: 168.17070627537186
Params: {'n_layer': 4, 'n_head': 4, 'n_embd': 256, 'learning_rate': 0.001, 'batch_size': 32}, Final Perplexity: 175.53690942399786
Params: {'n_layer': 4, 'n_head': 4, 'n_embd': 256, 'learning_rate': 0.0001, 'batch_size': 16}, Final Perplexity: 343.9269490535989
Params: {'n_layer': 4, 'n_head': 4, 'n_embd': 256, 'learning_rate': 0.0001, 'batch_size': 32}, Final Perplexity: 316.03690160295696
Params: {'n_layer': 8, 'n_head': 2, 'n_embd': 128, 'learning_rate': 0.001, 'batch_size': 16}, Final Perplexity: 307.2908212079723
Params: {'n_layer': 8, 'n_head': 2, 'n_embd': 128, 'learning_rate': 0.001, 'batch_size': 32}, Final Perplexity: 277.62169682093247
Params: {'n_layer': 8, 'n_head': 2, 'n_embd': 128, 'learning_rate': 0.0001, 'batch_size': 16}, Final Perplexity: 556.60522768656
Params: {'n_layer': 8, 'n_head': 2, 'n_embd': 128, 'learning_rate': 0.0001, 'batch_size': 32}, Final Perplexity: 515.3920649644439
Params: {'n_layer': 8, 'n_head': 2, 'n_embd': 256, 'learning_rate': 0.001, 'batch_size': 16}, Final Perplexity: 166.00108329250693
Params: {'n_layer': 8, 'n_head': 2, 'n_embd': 256, 'learning_rate': 0.001, 'batch_size': 32}, Final Perplexity: 188.3023877479292
Params: {'n_layer': 8, 'n_head': 2, 'n_embd': 256, 'learning_rate': 0.0001, 'batch_size': 16}, Final Perplexity: 306.47581798268607
Params: {'n_layer': 8, 'n_head': 2, 'n_embd': 256, 'learning_rate': 0.0001, 'batch_size': 32}, Final Perplexity: 266.6293341389688
Params: {'n_layer': 8, 'n_head': 4, 'n_embd': 128, 'learning_rate': 0.001, 'batch_size': 16}, Final Perplexity: 299.4915748807982
Params: {'n_layer': 8, 'n_head': 4, 'n_embd': 128, 'learning_rate': 0.001, 'batch_size': 32}, Final Perplexity: 279.1986624345878
Params: {'n_layer': 8, 'n_head': 4, 'n_embd': 128, 'learning_rate': 0.0001, 'batch_size': 16}, Final Perplexity: 551.6588977314324
Params: {'n_layer': 8, 'n_head': 4, 'n_embd': 128, 'learning_rate': 0.0001, 'batch_size': 32}, Final Perplexity: 487.93150964773196
Params: {'n_layer': 8, 'n_head': 4, 'n_embd': 256, 'learning_rate': 0.001, 'batch_size': 16}, Final Perplexity: 170.87637827969206
Params: {'n_layer': 8, 'n_head': 4, 'n_embd': 256, 'learning_rate': 0.001, 'batch_size': 32}, Final Perplexity: 205.47747715044457
Params: {'n_layer': 8, 'n_head': 4, 'n_embd': 256, 'learning_rate': 0.0001, 'batch_size': 16}, Final Perplexity: 301.6985295426131
Params: {'n_layer': 8, 'n_head': 4, 'n_embd': 256, 'learning_rate': 0.0001, 'batch_size': 32}, Final Perplexity: 273.49760834464246
